# ğŸ›¡ï¸ SystÃ¨me de DÃ©tection de Fraude par Machine Learning

## ğŸ“‹ Description du Projet

Ce projet implÃ©mente un systÃ¨me de dÃ©tection de fraude bancaire utilisant des techniques de Machine Learning. Il traite un dataset dÃ©sÃ©quilibrÃ© de transactions financiÃ¨res et utilise des mÃ©thodes d'undersampling et de SMOTE pour crÃ©er un modÃ¨le de classification efficace.

## ğŸ¯ Objectifs

- DÃ©tecter les transactions frauduleuses dans un dataset bancaire
- GÃ©rer le dÃ©sÃ©quilibre extrÃªme des classes (fraude vs non-fraude)
- Ã‰viter l'overfitting et le data leakage
- Obtenir un modÃ¨le performant et gÃ©nÃ©ralisable

## ğŸ“Š Dataset

**Fichier source :** `fraudTrain.csv`

**CaractÃ©ristiques :**
- Nombre initial de transactions : ~1,296,675
- Distribution initiale : ~0.58% de fraudes (hautement dÃ©sÃ©quilibrÃ©)
- Features : 23 colonnes incluant montants, catÃ©gories, informations gÃ©ographiques, etc.

### Colonnes principales :
- `is_fraud` : Variable cible (0 = lÃ©gitime, 1 = fraude)
- `amt` : Montant de la transaction
- `category` : CatÃ©gorie de dÃ©pense
- `lat`, `long` : CoordonnÃ©es gÃ©ographiques
- Features dÃ©mographiques et temporelles

## ğŸ”§ Technologies UtilisÃ©es

```python
- Python 3.x
- pandas : Manipulation de donnÃ©es
- numpy : Calculs numÃ©riques
- scikit-learn : ModÃ¨les ML et mÃ©triques
- imbalanced-learn : Gestion du dÃ©sÃ©quilibre (SMOTE)
- matplotlib/seaborn : Visualisation (optionnel)
```

## ğŸ“¦ Installation

```bash
# Cloner le repository
git clone <votre-repo>
cd fraud-detection

# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install pandas numpy scikit-learn imbalanced-learn matplotlib seaborn
```

## ğŸš€ Utilisation

### 1. PrÃ©paration des donnÃ©es

```python
python prepare_data.py
```

Cette Ã©tape :
- Charge le dataset `fraudTrain.csv`
- Applique l'undersampling (rÃ©duction de 1,100,000 transactions non-frauduleuses)
- MÃ©lange alÃ©atoirement les donnÃ©es

### 2. EntraÃ®nement du modÃ¨le

```python
python train_model.py
```

Pipeline complet :
1. **Undersampling** : RÃ©duction Ã  50,000 transactions non-frauduleuses
2. **Split Train/Test** : 80/20 stratifiÃ©
3. **SMOTE** : Oversampling de la classe minoritaire (uniquement sur train)
4. **EntraÃ®nement** : Random Forest avec hyperparamÃ¨tres optimisÃ©s
5. **Ã‰valuation** : MÃ©triques dÃ©taillÃ©es sur le test set

### 3. Ã‰valuation et prÃ©diction

```python
python evaluate_model.py
```

## ğŸ“ˆ RÃ©sultats Attendus

### Distribution des classes aprÃ¨s traitement :

```
Avant undersampling :
- Classe 0 (non-fraude) : 1,289,169
- Classe 1 (fraude) : 7,506

AprÃ¨s undersampling :
- Classe 0 : 50,000
- Classe 1 : 7,506

AprÃ¨s SMOTE (train uniquement) :
- Classe 0 : ~40,000
- Classe 1 : ~32,000 (ratio 0.8)
```

### MÃ©triques de performance :

- **Accuracy** : 85-95% (sur test set)
- **Precision** : Minimiser les faux positifs
- **Recall** : Maximiser la dÃ©tection des vraies fraudes
- **F1-Score** : Ã‰quilibre entre precision et recall

## âš ï¸ ProblÃ¨mes Courants et Solutions

### 1. Accuracy = 100% (Overfitting)

**Causes :**
- Data leakage (colonnes qui rÃ©vÃ¨lent la target)
- SMOTE appliquÃ© avant le split train/test
- Colonnes ID ou timestamps incluses

**Solutions :**
```python
# Exclure les colonnes suspectes
colonnes_a_exclure = ['trans_num', 'unix_time', 'trans_date_trans_time']

# SMOTE APRÃˆS le split
X_train, X_test = train_test_split(...)
X_train_resampled = smote.fit_resample(X_train)  # Seulement sur train !
```

### 2. Classes non mÃ©langÃ©es

**ProblÃ¨me :** Les 0 et 1 sont groupÃ©s ensemble

**Solution :**
```python
df = df.sample(frac=1, random_state=42).reset_index(drop=True)
```

### 3. MÃ©moire insuffisante

**Solution :** Augmenter l'undersampling initial
```python
sampled_non_fraud = non_fraud_df.sample(n=30000, random_state=42)  # RÃ©duire Ã  30k
```

## ğŸ“ Structure du Projet

```
fraud-detection/
â”‚
â”œâ”€â”€ fraudTrain.csv              # Dataset brut
â”œâ”€â”€ prepare_data.py             # Script de prÃ©paration
â”œâ”€â”€ train_model.py              # Script d'entraÃ®nement
â”œâ”€â”€ evaluate_model.py           # Script d'Ã©valuation
â”œâ”€â”€ fraud_correct_pipeline.py   # Pipeline complet
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ README.md                   # Ce fichier
â”‚
â”œâ”€â”€ models/                     # ModÃ¨les sauvegardÃ©s
â”‚   â””â”€â”€ fraud_detector.pkl
â”‚
â”œâ”€â”€ results/                    # RÃ©sultats et visualisations
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ metrics_report.txt
â”‚
â””â”€â”€ notebooks/                  # Notebooks d'exploration
    â””â”€â”€ exploration.ipynb
```

## ğŸ” Bonnes Pratiques ImplÃ©mentÃ©es

1. âœ… **Split avant SMOTE** : Ã‰vite le data leakage
2. âœ… **Stratified split** : Maintient la distribution des classes
3. âœ… **MÃ©lange alÃ©atoire** : Ã‰vite les patterns liÃ©s Ã  l'ordre
4. âœ… **Exclusion des colonnes suspectes** : PrÃ©vient le data leakage
5. âœ… **Limitation de la profondeur** : RÃ©duit l'overfitting
6. âœ… **Random state fixe** : ReproductibilitÃ© des rÃ©sultats

## ğŸ“Š Visualisations

### Matrice de confusion
```python
import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de Confusion')
plt.ylabel('Vraie classe')
plt.xlabel('Classe prÃ©dite')
plt.savefig('results/confusion_matrix.png')
```

### Importance des features
```python
feature_importance.plot(kind='barh', x='feature', y='importance', figsize=(10, 8))
plt.title('Top Features pour la DÃ©tection de Fraude')
plt.savefig('results/feature_importance.png')
```

## ğŸš§ AmÃ©liorations Futures

- [ ] Tester d'autres algorithmes (XGBoost, LightGBM, Neural Networks)
- [ ] Optimisation des hyperparamÃ¨tres (GridSearchCV, RandomizedSearchCV)
- [ ] Feature engineering avancÃ©
- [ ] Validation croisÃ©e stratifiÃ©e
- [ ] DÃ©ploiement API (Flask/FastAPI)
- [ ] Monitoring en production
- [ ] Interface utilisateur web

## ğŸ“ Notes Importantes

### Data Leakage - Colonnes Ã  exclure :
- `trans_num` : Identifiant unique de transaction
- `unix_time` : Timestamp exact
- `trans_date_trans_time` : Date/heure complÃ¨te
- Toute colonne calculÃ©e APRÃˆS la fraude

### MÃ©triques Prioritaires :
Pour la dÃ©tection de fraude, privilÃ©gier :
1. **Recall** : Ne pas manquer de vraies fraudes (coÃ»t Ã©levÃ©)
2. **Precision** : Ã‰viter trop de faux positifs (expÃ©rience client)
3. **F1-Score** : Ã‰quilibre global

## ğŸ‘¥ Contribution

Les contributions sont les bienvenues ! 

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commit les changements (`git commit -m 'Ajout nouvelle feature'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ“§ Contact

Pour toute question ou suggestion :
- Email : votre.email@example.com
- GitHub : [@votre-username](https://github.com/votre-username)

## ğŸ™ Remerciements

- Dataset source : [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/)
- Librairie imbalanced-learn pour SMOTE
- CommunautÃ© scikit-learn

---

**âš¡ DerniÃ¨re mise Ã  jour :** Novembre 2025  
**ğŸ“Œ Version :** 1.0.0
